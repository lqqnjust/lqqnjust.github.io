{"meta":{"title":"清风竹影","subtitle":"","description":"","author":"imqq1210","url":"http://example.com","root":"/"},"pages":[{"title":"categories","date":"2020-09-24T08:35:16.000Z","updated":"2020-09-24T09:21:10.120Z","comments":false,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"about","date":"2020-09-24T08:57:29.000Z","updated":"2020-09-24T12:18:10.583Z","comments":true,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":"Hello, it’s me!"},{"title":"tags","date":"2020-09-24T08:35:47.000Z","updated":"2020-09-24T09:20:42.880Z","comments":false,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"kafka学习（一）","slug":"kafka学习（一）","date":"2020-09-25T01:24:11.000Z","updated":"2020-09-25T07:42:09.165Z","comments":true,"path":"2020/09/25/kafka学习（一）/","link":"","permalink":"http://example.com/2020/09/25/kafka%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89/","excerpt":"","text":"流处理平台特性 可以发布（write）和订阅（read）事件流，包括持续的从其他系统导入、导出数据。 可以存储流式记录，并且有较好的容错性。 可以在流式数据产生时就处理 kafka适用场景 构造实时数据流管道，可以在系统或者应用之间可靠的获取数据。（消息队列） 构建实时流式应用程序，对这些流数据进行转换或者影响。（流处理，通过kafka stream topic和topic之间内部进行变化） kafka特性 kafka作为集群，运行在一台或者多台服务器上 通过topic对存储的流数据进行分类 每条记录中包含一个key，一个value和一个timstamp API Admin API管理和检查topics，brokers和其他kafka对象。 Producer API允许一个应用发布以传流式的数据到一个或者多个topic中 Consumer API允许一个应用订阅一个或者多个topic，并且对发布给他们的流式数据处理 Stream API允许一个应用程序作为一个流处理器，消费一个或者多个topic产生的输入流，然后生产一个输出流到一个或者多个topic中取，在输入输出流中进行有效的转换 Connector API允许构建并且运行可重用的生产者消费者，将kafka topics连接到已经存在的应用程序或者数据系统。比如，连接到一个关系型数据库，捕捉表的所有变更内容。 Topics和日志Topic就是数据主题，是数据记录发布的地方，可以用来区分业务系统。Topics是多订阅者模式，一个topic可以拥有一个或者多个消费者来订阅它的数据。 每一个topic，集群为维持一个分区日志，如下图： 每个分区都是有序且顺序不可变的记录集，并且不断地追加到结构化的commit log文件。分区中每一个记录都会分配一个id号来表示顺序，称之为offset。offset用来唯一标识分区中的每一条记录。 kafka集群保留所有发布的记录，无论他们是否已经被消费掉，并且通过一个可配置的参数：保留期限 来控制。kafka的性能和数据大小无关。 在每个消费中唯一保存的元数据是offset，即消费在log中的位置。偏移量是由消费者控制，通常在读取记录后，消费者会以线性的方式增加偏移量。但在实际中，由于这个位置由消费者控制，所以消费者可以通过任何顺序来消费记录。 分布式日志的分区partition在kafka集群的服务器上。每个服务器在处理数据和请求时，共享这些分区。每一个分区都会在已配置的服务器上进行备份，确保容错性。 每个分区都有一台server作为leader。leader server处理一切对partition的读写请求，而follower只需被动的同步leader的数据。当leader宕机了，followers中的一台服务器会自动成为新的leader。每台server都会成为某些分区的leader和某些分区的follower。 生产者生产者发布数据到所选择的topic中。生产者负责将记录分配到topic的哪一个分区中。可以使用循环的方式来简单的实现负载均衡，也可以根据某些语义分区函数来完成。 消费者消费者使用一个消费组名称来进行标识。发布到topic中的每条记录被分配给订阅消费组中的一个消费者实例。消费者实例可以分布在多个进程中或者多个机器上。如果所有的消费者实例在同一个消费组，消息记录会负载平衡到每一个消费者实例。如果所有的消费者实例在不同的消费组中，每条消息记录会广播到所有的消费者进程。","categories":[{"name":"分布式","slug":"分布式","permalink":"http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"http://example.com/tags/kafka/"}]},{"title":"Hello World","slug":"hello-world","date":"2020-09-24T08:09:10.770Z","updated":"2020-09-24T08:09:10.770Z","comments":true,"path":"2020/09/24/hello-world/","link":"","permalink":"http://example.com/2020/09/24/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post$ hexo new &quot;My New Post&quot; More info: Writing Run server$ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[{"name":"分布式","slug":"分布式","permalink":"http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"http://example.com/tags/kafka/"}]}